## 《机器学习：Machine Learning》学习笔记

#教材信息

- 周志华主编
- 清华大学出版社（北京）出版
- 2016年1月第一版

#笔记作者

**`From Felix Du`**

------

[TOC]

------

### 前言

#### 本书结构

- 第一部分（1~3章）：机器学习基础知识
- 第二部分（4~10章）：经典而常用的机器学习方法
- 第三部分（11~16章）：进阶知识

#### 一些观点

- 统计技术和认知结构深刻理解结合起来是十分有必要的
- [独立同分布_](https://baike.baidu.com/item/独立同分布/6715110)的不存在难道就无法进行机器学习了吗？迁移学习是一个解决问题的思路
- 深度学习源自于硬件水平的提高，但是深度学习可以取代统计机器学习了吗？还远远不到：
  - 一是深度学习的理论创新还不明显
  - 二是目前的深度学习主要适合神经网络，并不能应用于一切机器学习方法
  - 三是统计学习在机器学习中被有效地普遍采用，不容易抛弃
- ”出面露头的是概率和统计，埋头苦干的是代数和逻辑“ 我们期待有更多数学家的参与，开辟机器学习的新模式、新理论、新方向。
- 符号机器学习时代主要以离散方法处理问题，统计机器学习时代主要以连续的方法处理问题。”这两种方法之间应该没有一条鸿沟“
- 大数据时代给统计机器学习提供了更多的机遇。我们要思考大数据时代在呼唤什么样的机器学习方法？哪些机器学习方法又是由于大数据研究的驱动而产生的？
- 我们欣慰的是国内不但有周志华教授这样的机器学习领军任务，而且比周教授年轻的许多机器学习青年才俊也成长起来了，中国的机器学习大有希望。

------

### 第一章：绪论

#### 1、引言

##### 1）什么是机器学习

​	机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。机器学习所研究的主要内容，是关于在计算机上从数据产生”模型“的算法，即”学习算法“，再把数据提供给算法，产生相应的模型。$y=f(x)$，需要我们让计算机在已知x和y的前提下，得出f的对应关系。

#### 2、基本术语

- ==数据集(data set)==：一组记录的集合，如一批关于西瓜的描述
- ==示例(instance)/样本(sample)==：一个事件或对象的描述，如关于一个西瓜的描述
- ==属性(attribute)/特征(feature)==：反映事件或对象在某方面的表现或性质，如色泽、根蒂这些西瓜的特征
- ==属性值(attribute value)==：属性上的取值，如青绿、乌黑等描述西瓜色泽的属性值
- ==属性空间(attribute space)/样本空间(sample space)==：属性张成的空间，如把色泽、根蒂、敲声作为三个坐标轴，张成一个描述西瓜的三维空间。
- ==维数(dimensionality)：==用于张成空间的属性数，三维空间的维数就是3
- ==学习(learning)/训练(training)：==从数据中学得模型的过程
- ==训练数据(training data)==：训练过程中使用的数据
- ==训练集(training set)==：训练样本组成的集合
- ==训练样本(training sample)==：训练数据中的每个样本
- ==假设(hypothesis)==：学得模型对应了关于数据的某种潜在的规律
- ==真相/真实(ground-truth)==：这种潜在规律自身
- ==学习器(learner)==：模型的另一种称呼，可看作学习算法在给定数据和参数空间上的实例化
- ==标记(label)==：对于我们训练示例结果的信息，比如（色泽=青绿；根蒂=蜷缩；敲声=浊响）== 好瓜中的好瓜
- ==样例(example)：==标记好的信息
- ==分类(classification)==：预测的是离散值，如好瓜，坏瓜
  - 涉及两个类别的二分类任务(binary classification)，其中一个称为==正类(positive class)==，另一个称为==反类(negative class==)
  - 涉及多个类别时，称为==多分类任务(multi-class classification)==
- ==回归(regression====)==：预测的是连续值，如西瓜的成熟度0.95
- ==测试(testing)==：学得模型后，使用其进行预测的过程，被预测的样本称为预测样本(testing sample)
- ==聚类(clustering)：==将训练集中的西瓜分成若干组，每组称为一个“簇”(cluster)
- ==监督学习(supervised learning)：==训练数据有标记信息，比如分类和回归
- ==无监督学习(unsupervised learning)==：训练数据无标记信息，比如聚类
- ==泛化(generalization)==：学得模型适用于新样本的能力，我们要追求泛化能力强的模型。通常假设样本空间中全体样本服从一个未知的”分布“D，我们获得的每个样本都是独立地从这个分布上采样获得的，即”独立同分布“。一般来说，训练的样本越多，我们得到的关于D的信息就越多，越能得到有强泛化能力的模型。

#### 3、假设空间

>主要是灌输一个想法，用来辅助后面算法学习中的一些基本思路

##### 1）归纳和演绎

- ==归纳(induction)==：从特殊到一般的泛化过程，比如从“特殊的瓜”（数据集）的例子，到一般的“什么是好瓜”的规律
- ==演绎(deduction)：==从一般到特殊的特化(specialization)过程，比如已经知道了什么是好瓜，来判断具体这个瓜是不是好的

​	我们研究的主要是归纳学习

##### 2）归纳学习

- 广义：从样本中学习规律
- 狭义：从训练数据中学得概念(concept)，因此称为“概念学习”或“概念形成”。目前几乎没有算法可以对应这种狭义的归纳学习，常见的技术大多是“黑箱”模型中

##### 3）假设空间的定义

​	比如，我们要学得模型，什么样的瓜是好瓜，我们要能够通过数据集，得出（色泽=？） ^ （根蒂=？） ^ （敲声=？）能推出是好瓜，任务就是把？的数值给确定下来；那么这样子的话我们要考虑不同参数的取值可能，比如，若 “色泽”“根蒂”“敲声”分别有3、2、2 种可能取值，则我 们面临的假设空间规模大小为4 x 3 x 3 + 1 = 37（其中包括“好瓜概念不存在”，是空集）

#### 4、归纳偏好
